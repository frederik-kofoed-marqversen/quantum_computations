{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes this notebook see the module from one folder above to allow imports from sibling folders!\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import json\n",
    "from colour import Colour\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# params = {\"text.usetex\" : True,\n",
    "#           \"font.family\" : \"serif\",\n",
    "#           \"font.serif\" : [\"Computer Modern Serif\"],\n",
    "#           'font.size': 22,}\n",
    "# mpl.rcParams.update(params)\n",
    "\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bar_kwargs = {\"capsize\": 5, \"linewidth\": 2, \"elinewidth\": 1, \"capthick\": 1, \"markersize\": 10}\n",
    "\n",
    "def eps2db(epsilon: float) -> float:\n",
    "    return -10.0 * np.log10(2.0 * np.tanh(epsilon / 2.0))\n",
    "\n",
    "def db2eps(db_squeezing: float) -> float:\n",
    "    return 2.0 * np.atanh(np.float_power(10.0, -db_squeezing / 10.0) / 2.0)\n",
    "\n",
    "def int2tag(n: int, N: int=0) -> str:\n",
    "    return \"{0:0{1}b}\".format(n, N)\n",
    "\n",
    "def tag2int(tag: str) -> int:\n",
    "    return int(tag, 2)\n",
    "\n",
    "\n",
    "# Grover error estimate\n",
    "from scipy.special import erf\n",
    "\n",
    "# Functions based on B. W. Walshe et al. Streamlined quantum computing with macronode cluster states. Jan. 2022\n",
    "\n",
    "def analytical_gate_error(db: float, integer: int) -> float:\n",
    "    # Input quadrature variance\n",
    "    var = integer * db2eps(db) / 2\n",
    "    # Success probability rates in each quadrature\n",
    "    success_rates = erf(np.sqrt(np.pi / (8 * var)))\n",
    "    return 1 - success_rates\n",
    "\n",
    "def gate_error_I(db):\n",
    "    return 1 - (1 - analytical_gate_error(db, 2)) * (1 - analytical_gate_error(db, 2))\n",
    "\n",
    "def gate_error_P(db):\n",
    "    return 1 - (1 - analytical_gate_error(db, 2)) * (1 - analytical_gate_error(db, 3))\n",
    "\n",
    "def grover_with_error_estimate(db) -> float:\n",
    "    r = (gate_error_I(db) + gate_error_P(db)) / 2\n",
    "    N = 3 # number of qubits\n",
    "    k = 2 # number of solutions\n",
    "    d = 18 # circuit depth\n",
    "\n",
    "    p_no_err = 1 - 4/3 * r\n",
    "    p_no_err = p_no_err**(d * N)\n",
    "    p_err = 1 - p_no_err\n",
    "\n",
    "    p_success = p_no_err + k / 2**N * p_err\n",
    "\n",
    "    return p_success"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot GKP randomised benchmarking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve clifford survival fidelity data\n",
    "paths = [\n",
    "    \"./data/gkp_cliff.dat\",\n",
    "]\n",
    "\n",
    "samples = []\n",
    "for path in paths:\n",
    "    with open(path, 'r') as file:\n",
    "        samples += json.load(file)\n",
    "\n",
    "# Sort samples by squeezing\n",
    "dbs = np.linspace(5, 15, 13)[:2]\n",
    "fidelities = [[] for _ in range(len(dbs))]\n",
    "for s in samples:\n",
    "    i = np.abs(dbs - s[\"db\"]).argmin()\n",
    "    fidelities[i] += s[\"fidelities\"]\n",
    "\n",
    "# Compute averages\n",
    "means = np.mean(fidelities, axis=1)\n",
    "print(means)\n",
    "print([len(a) for a in fidelities])\n",
    "\n",
    "# Plot\n",
    "plt.figure()\n",
    "plt.axhline(1/4, color='0', linestyle='-')\n",
    "for db, fs in zip(dbs, fidelities):\n",
    "    plt.plot([db]*len(fs), fs, \"k*\", label=\"Fidelities\")\n",
    "plt.plot(dbs, means, \"ro\", label=\"Averages\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"GKP squeezing (dB)\")\n",
    "plt.ylabel(\"Clifford survival fidelity.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def process_rb_samples(samples: list[dict]) -> tuple[dict, dict]:\n",
    "    # Sort samples by depth\n",
    "    depths = [s[\"depth\"] for s in samples]\n",
    "    depths = sorted(set(depths))\n",
    "    fidelities = []\n",
    "    purities = []\n",
    "    for depth in depths:\n",
    "        fs = []\n",
    "        ps = []\n",
    "        for s in samples:\n",
    "            if not np.isclose(s[\"depth\"], depth):\n",
    "                continue\n",
    "            fs.append(s[\"fidelity\"])\n",
    "            ps.append(s[\"purity\"])\n",
    "        fidelities.append(fs)\n",
    "        purities.append(ps)\n",
    "\n",
    "    print([len(arr) for arr in fidelities])\n",
    "    fidelity_data = {\n",
    "        \"depths\": depths,\n",
    "        \"samples\": fidelities,\n",
    "        \"means\": [np.mean(arr) for arr in fidelities],\n",
    "        \"errors\": [np.std(arr)/np.sqrt(len(arr)) for arr in fidelities],\n",
    "    }\n",
    "\n",
    "    purity_data = {\n",
    "        \"depths\": depths,\n",
    "        \"samples\": purities,\n",
    "        \"means\": [np.mean(arr) for arr in purities],\n",
    "        \"sample_std\": [np.std(arr) for arr in purities],\n",
    "    }\n",
    "\n",
    "    return fidelity_data, purity_data\n",
    "\n",
    "def fidelity_analysis(data: dict) -> dict:\n",
    "    depths = data[\"depths\"]\n",
    "    avg_fidelity = data[\"means\"]\n",
    "    avg_fidelity_error = data[\"errors\"]\n",
    "    \n",
    "    # Fit error rate\n",
    "    def exp_decay(m, a, p):\n",
    "        return a * p**m + 1/4\n",
    "    p_guess = (4 / 3 *(avg_fidelity[-1] - 1/4))**(1/depths[-1])\n",
    "    initial_guess = [3/4, p_guess]\n",
    "\n",
    "    popt, pcov = curve_fit(exp_decay, depths, avg_fidelity, sigma=avg_fidelity_error, absolute_sigma=True, p0=initial_guess)\n",
    "\n",
    "    fit = lambda m: exp_decay(m, *popt)\n",
    "    p = popt[1]\n",
    "    p_err = np.sqrt(pcov[1, 1])\n",
    "\n",
    "    num_qubits = 2 # Fixed at 2\n",
    "    avg_error_rate = (1-p) * (1 - 2**-num_qubits)\n",
    "    avg_error_rate_error = p_err * (1 - 2**-num_qubits)\n",
    "\n",
    "    results = {\n",
    "        \"p\": p,\n",
    "        \"p_err\": p_err,\n",
    "        \"fit\": fit,\n",
    "        \"r\": avg_error_rate,\n",
    "        \"r_err\": avg_error_rate_error,\n",
    "    }\n",
    "\n",
    "    return results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve RB data\n",
    "path = \"./data/gkp_rb.dat\"\n",
    "with open(path, 'r') as file:\n",
    "    samples = json.load(file)\n",
    "\n",
    "# Data analysis\n",
    "\n",
    "# Sort data by squeezing\n",
    "dbs = np.linspace(5, 15, 13)\n",
    "samples_sorted = [[] for _ in range(len(dbs))]\n",
    "\n",
    "for sample in samples:\n",
    "    db = sample[\"db\"]\n",
    "    if db > 12:\n",
    "        continue\n",
    "    i = np.abs(dbs - db).argmin()\n",
    "    samples_sorted[i].append(sample)\n",
    "\n",
    "# Remove empty data\n",
    "dbs = dbs.tolist()\n",
    "i = 0\n",
    "while i < len(dbs):\n",
    "    if len(samples_sorted[i]) == 0:\n",
    "        dbs.pop(i)\n",
    "        samples_sorted.pop(i)\n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "processed = [process_rb_samples(samples) for samples in samples_sorted]\n",
    "fidelity_results = [fidelity_analysis(p[0]) for p in processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plotting each dB individually\n",
    "# for db, (f, _), r in zip(dbs, processed, fidelity_results, strict=True):\n",
    "#     temp = r.copy()\n",
    "#     temp.pop(\"fit\")\n",
    "#     print(temp)\n",
    "    \n",
    "#     ds = f[\"depths\"]\n",
    "#     plt.figure()\n",
    "#     plt.plot(ds, f[\"samples\"], \"*\", color=\"0.8\")\n",
    "#     plt.errorbar(ds, f[\"means\"], 2 * np.array(f[\"errors\"]), fmt=\"k.\", **error_bar_kwargs)\n",
    "#     xs = np.linspace(min(ds), max(ds), 100)\n",
    "#     plt.plot(xs, r[\"fit\"](xs), \"r-\")\n",
    "    \n",
    "#     plt.xlabel(\"Circuit depth\")\n",
    "#     plt.ylabel(\"Output fidelity\")\n",
    "#     plt.show()\n",
    "\n",
    "# Plot fitted functions\n",
    "plt.figure(figsize=(8, 4))\n",
    "cmap = mpl.colormaps['grey']\n",
    "colors = cmap(np.linspace(0, 1, len(dbs)))\n",
    "for i, db, (f, _), r, c in zip(range(len(dbs)), dbs, processed, fidelity_results, colors, strict=True):\n",
    "    ds = f[\"depths\"]\n",
    "    xs = np.linspace(min(ds)-1, 60, 100)\n",
    "    ys = r[\"fit\"](xs)\n",
    "    c = \"0.5\" if i%2==0 else \"0.0\"\n",
    "    err_bar = plt.errorbar(ds, f[\"means\"], np.array(f[\"errors\"]), fmt=\".\", color=c, **error_bar_kwargs)\n",
    "    fit_line, = plt.plot(xs, ys, \"-\", color=c)\n",
    "    \n",
    "    idx = 5+5*i\n",
    "    plt.text(xs[idx], ys[idx], \"{:.2f} dB\".format(db), fontsize=10, va='center', ha='center',\n",
    "             bbox=dict(facecolor='white', alpha=0.8, edgecolor='none', boxstyle='round,pad=0.2'))\n",
    "err_bar.set_label(\"Numerical estimates\")\n",
    "fit_line.set_label(\"Fit\")\n",
    "plt.xlabel(\"Circuit depth\")\n",
    "plt.ylabel(\"Average output fidelity\")\n",
    "# plt.legend()\n",
    "plt.xlim(0, 65)\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()   \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gate errors\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, figsize=(8, 5), height_ratios=(3, 1))\n",
    "error_rate = np.array([e[\"r\"] for e in fidelity_results])\n",
    "error_rate_std = np.array([e[\"r_err\"] for e in fidelity_results])\n",
    "# # r^* = sqrt(r)\n",
    "# # var(r^*) = (dr^*/dr)^2 var(r) = (2 sqrt(r))^-2 var(r)\n",
    "# gate_error_rate = np.sqrt(error_rate)\n",
    "# gate_error_rate_std = error_rate_std / (2 * gate_error_rate)\n",
    "\n",
    "ax1.errorbar(dbs, error_rate, error_rate_std, fmt=\"k.\", **error_bar_kwargs, label=\"Numerical estimate\")\n",
    "# Analytical\n",
    "xs = np.linspace(5, 15, 100)\n",
    "ax1.plot(xs, [gate_error_I(x) for x in xs], \"-\", color=\"0.5\", label=\"Analytical estimate\")\n",
    "ax1.plot(xs, [gate_error_P(x) for x in xs], \"-\", color=\"0.5\")\n",
    "ax1.plot(xs, [(gate_error_I(x) + gate_error_P(x))/2 for x in xs], \"--\", color=\"0.5\", label=\"Mean of analytics\")\n",
    "\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlim(5.5, 12.5)\n",
    "ax1.set_ylim(1.5e-4, 1.1)\n",
    "ax1.set_ylabel(\"Average gate error rate\")\n",
    "ax1.grid(which=\"both\")\n",
    "ax1.legend()\n",
    "\n",
    "# Normalised residuals\n",
    "mean = np.array([(gate_error_I(db) + gate_error_P(db))/2 for db in dbs])\n",
    "residuals = (error_rate - mean) / error_rate_std\n",
    "ax2.plot(dbs, residuals, \"k*\")\n",
    "ax2.axhline(0, color=\"0.5\", linestyle=\"--\")\n",
    "ax2.set_ylim(-3.5, 3.5)\n",
    "ax2.set_ylabel(\"Normalised residuals\")\n",
    "ax2.set_xlabel(\"GKP squeezing (dB)\")\n",
    "ax2.grid(axis=\"x\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Plot logical purities\n",
    "# plt.figure()\n",
    "# for db, (_, p), c in zip(dbs, processed, colors, strict=True):\n",
    "#     ds = p[\"depths\"]\n",
    "#     xs = np.linspace(min(ds), max(ds), 100)\n",
    "#     plt.errorbar(ds, p[\"means\"], np.array(p[\"sample_std\"]), fmt=\".\", color=c, label=\"{:.2f} dB\".format(db), **error_bar_kwargs)\n",
    "# plt.xlabel(\"Circuit depth\")\n",
    "# plt.ylabel(\"Output fidelity\")\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot GKP grover simulation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retreive simulation data\n",
    "N = 3\n",
    "solutions = [(0, 4), (2, 7), (3, 6)]\n",
    "paths = [\n",
    "    \"./data/gkp_grover_04.dat\",\n",
    "    \"./data/gkp_grover_27.dat\",\n",
    "    \"./data/gkp_grover_36.dat\",\n",
    "]\n",
    "\n",
    "entries = []\n",
    "for path in paths:\n",
    "    with open(path, 'r') as file:\n",
    "        entries.append(json.load(file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Pretty print runs (for debugging)\n",
    "# for entry in entries[0]:\n",
    "#     db = round(eps2db(entry[\"epsilon\"]), 4)\n",
    "#     print(f\"Sim with {db}dB of squeezing.\")\n",
    "#     for i, p in enumerate(np.diag(entry[\"rho_real\"])):\n",
    "#         string = int2tag(i, 3)\n",
    "#         string = f\"{string} : {p:1.4f}\"\n",
    "#         if i in [2, 7]:\n",
    "#             string = Colour.colour_this(string, Colour.OKGREEN, Colour.BOLD)\n",
    "#         elif p > 0.1:\n",
    "#             string = Colour.colour_this(string, Colour.FAIL, Colour.BOLD)\n",
    "#         print(string)\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data\n",
    "processed = []\n",
    "\n",
    "dbs = np.linspace(5, 15, 13)[2:-1]  # remove less interesting regimes\n",
    "for entry_sol, entry_data in zip(solutions, entries):\n",
    "    # dbs = sorted(set(eps2db(e[\"epsilon\"]) for e in entry_data))\n",
    "    \n",
    "    success = [[] for _ in range(len(dbs))]\n",
    "    for entry in entry_data:\n",
    "        db = eps2db(entry[\"epsilon\"])\n",
    "        i = np.abs(dbs - db).argmin()\n",
    "        if abs(db - dbs[i]) > 1e-6:\n",
    "            continue\n",
    "        ps = np.diag(entry[\"rho_real\"])\n",
    "        p = sum(ps[n] for n in entry_sol)\n",
    "        success[i].append(p)\n",
    "    \n",
    "    averages = [np.mean(ps) if ps else float('NaN') for ps in success]\n",
    "    errors = [2*np.std(ps)/np.sqrt(len(ps)) if ps else float('NaN') for ps in success]\n",
    "    processed.append({\n",
    "        \"sols\": entry_sol,\n",
    "        \"dbs\": dbs,\n",
    "        \"ps\": success,\n",
    "        \"avgs\": averages,\n",
    "        \"errs\": errors,\n",
    "    })\n",
    "\n",
    "# Combine entries into a single data set\n",
    "combined = {\n",
    "    \"dbs\": dbs,\n",
    "    \"ps\": [[] for _ in range(len(dbs))],\n",
    "    \"avgs\": [],\n",
    "    \"errs\": [],\n",
    "}\n",
    "for entry in processed:\n",
    "    for i in range(len(combined[\"dbs\"])):\n",
    "        combined[\"ps\"][i] += entry[\"ps\"][i]\n",
    "combined[\"avgs\"] = [np.mean(ps) for ps in combined[\"ps\"]]\n",
    "combined[\"errs\"] = [2*np.std(ps)/np.sqrt(len(ps)) for ps in combined[\"ps\"]]\n",
    "\n",
    "# # Remove certain undersampled dBs\n",
    "# for key in combined.keys():\n",
    "#     combined[key] = combined[key][2:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot separate runs\n",
    "colors = [\"0.0\", \"0.25\", \"0.5\"]\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.axhline(13/28, color='0', linestyle='-')\n",
    "plt.axhline(2/8, color='0', linestyle='--')\n",
    "\n",
    "# # Plot samples\n",
    "# for entry, c in zip(processed, colors, strict=True):\n",
    "#     xs = entry[\"dbs\"]\n",
    "#     ys = entry[\"ps\"]\n",
    "#     for x0, y in zip(xs, ys):\n",
    "#         x = np.repeat([x0], len(y))\n",
    "#         plt.plot(x, y, c+\"*\", alpha=.1)\n",
    "# Plot averages and errors\n",
    "for entry, c in zip(processed, colors, strict=True):\n",
    "    tags = [int2tag(n, N) for n in entry[\"sols\"]]\n",
    "    label = \"Oracle: \" + \", \".join(tags)\n",
    "    averages = entry[\"avgs\"]\n",
    "    errors = entry[\"errs\"]\n",
    "    xs = entry[\"dbs\"]\n",
    "    plt.errorbar(xs, averages, errors, fmt=\".-\", color=c, label=label, **error_bar_kwargs)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"GKP squeezing (dB)\")\n",
    "plt.ylabel(\"Success probability\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Print combined data\n",
    "print(\"Sampled dBs:\", np.round(combined[\"dbs\"], 3).tolist())\n",
    "print(\"Number of samples:\", [len(ls) for ls in combined[\"ps\"]])\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.axhline(13/28, color='0', linestyle='-')\n",
    "plt.axhline(2/8, color='0', linestyle='--')\n",
    "\n",
    "xs = combined[\"dbs\"]\n",
    "ys = combined[\"ps\"]\n",
    "# for x0, y in zip(xs, ys):\n",
    "#     x = np.repeat([x0], len(y))\n",
    "#     obj, = plt.plot(x, y, \"*\", color=\"0.8\")\n",
    "# obj.set_label(\"Samples\")\n",
    "averages = combined[\"avgs\"]\n",
    "errors = combined[\"errs\"]\n",
    "plt.errorbar(xs, averages, errors, fmt=\"k.\", **error_bar_kwargs, label=\"Numerical data\")\n",
    "\n",
    "xs = np.linspace(dbs[0], dbs[-1], 100)\n",
    "plt.plot(xs, [grover_with_error_estimate(x) for x in xs], \"k-\", label=\"RB estimate\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"GKP squeezing (dB)\")\n",
    "plt.ylabel(\"Success probability\")\n",
    "plt.ylim(-0.05, 1.05)\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
